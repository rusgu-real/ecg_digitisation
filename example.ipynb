{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -rf clone && git clone https://github.com/rusgu-real/ecg_digitisation clone && cp -a clone/. ."
      ],
      "metadata": {
        "id": "Yt_ZVOaTgbIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hr-InVuk9g3b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bbdf733"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from abc import ABC, abstractmethod\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import deque\n",
        "\n",
        "class ImageData:\n",
        "    def __init__(self, image, metadata=None):\n",
        "        self.image = image\n",
        "        self.metadata = metadata if metadata is not None else {}\n",
        "\n",
        "    def show(self, text):\n",
        "      print(text)\n",
        "      cv2_imshow(self.image)\n",
        "\n",
        "class Processor(ABC):\n",
        "  @abstractmethod\n",
        "  def process(self, data:ImageData) -> ImageData:\n",
        "    pass\n",
        "\n",
        "class Crop(Processor):\n",
        "  def process(self, data:ImageData) -> ImageData:\n",
        "    orig = data.image\n",
        "    scale = 800 / orig.shape[1]\n",
        "    image = cv2.resize(orig, None, fx=scale, fy=scale)\n",
        "\n",
        "    # Grayscale + blur\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=1.0, tileGridSize=(8,8))\n",
        "    blur = clahe.apply(blur)\n",
        "\n",
        "    # Edge detection\n",
        "    edges = cv2.Canny(blur, 50, 200)\n",
        "    cv2_imshow(edges)\n",
        "\n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(\n",
        "        edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "    )\n",
        "\n",
        "    contours, _ = cv2.findContours(\n",
        "        edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "    )\n",
        "\n",
        "    if contours:\n",
        "        # Pick the largest contour regardless of approximation\n",
        "        paper_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "        # Optional: approximate its polygon for later perspective transform\n",
        "        peri = cv2.arcLength(paper_contour, True)\n",
        "        approx = cv2.approxPolyDP(paper_contour, 0.02 * peri, True)\n",
        "\n",
        "        # Use approx for warping or drawing\n",
        "        paper_contour = approx\n",
        "    else:\n",
        "        paper_contour = None  # No contours found\n",
        "\n",
        "\n",
        "    # Scale contour back to original size\n",
        "    paper_contour = (paper_contour / scale).astype(np.int32)\n",
        "\n",
        "    # Crop original image\n",
        "    x, y, w, h = cv2.boundingRect(paper_contour)\n",
        "    cropped = orig[y:y+h, x:x+w]\n",
        "    data.metadata[\"cropped\"] = cropped\n",
        "    data.metadata[\"paper_contour\"] = paper_contour\n",
        "    data.image = cropped # Pass the cropped image to the next processor\n",
        "    return data\n",
        "\n",
        "\n",
        "class Unwarp(Processor):\n",
        "    def process(self, data: ImageData) -> ImageData:\n",
        "        pass\n",
        "\n",
        "class GridDetect(Processor):\n",
        "  def process(self, data:ImageData) -> ImageData:\n",
        "    img = data.image # This will be the cropped image from the previous step\n",
        "\n",
        "    if img is None:\n",
        "        raise IOError(\"Image not found in data.image\")\n",
        "\n",
        "    h_img, w_img = img.shape[:2]\n",
        "    data.metadata[\"image_height\"] = h_img # Store image dimensions\n",
        "    data.metadata[\"image_width\"] = w_img\n",
        "\n",
        "    # --- Step 1: Detect red grid mask ---\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    lower_red1 = np.array([0,50,50])\n",
        "    upper_red1 = np.array([30,255,255])\n",
        "    lower_red2 = np.array([150,50,50])\n",
        "    upper_red2 = np.array([180,255,255])\n",
        "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
        "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
        "    red_mask = cv2.bitwise_or(mask1, mask2)\n",
        "\n",
        "    # Minimal morphology to clean noise\n",
        "    kernel = np.ones((2,2),np.uint8)\n",
        "    red_mask_clean = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "    data.metadata[\"red_mask_clean\"] = red_mask_clean\n",
        "    print(\"Step 1: Red grid mask cleaned\")\n",
        "    cv2_imshow(red_mask_clean)\n",
        "\n",
        "    # --- Step 2: Edge detection ---\n",
        "    edges = cv2.Canny(red_mask_clean, 20, 60)\n",
        "    print(\"Step 2: Edges detected for grid\")\n",
        "    cv2_imshow(edges)\n",
        "\n",
        "    # --- Step 3: Detect Hough lines ---\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=20, minLineLength=20, maxLineGap=15)\n",
        "    horizontal_lines = []\n",
        "    vertical_lines = []\n",
        "    if lines is not None:\n",
        "        for x1, y1, x2, y2 in lines[:,0]:\n",
        "            if abs(y1 - y2) < 5: # Horizontal line\n",
        "                horizontal_lines.append((x1, y1, x2, y2))\n",
        "            elif abs(x1 - x2) < 5: # Vertical line\n",
        "                vertical_lines.append((x1, y1, x2, y2))\n",
        "\n",
        "    grid_detected_img = img.copy()\n",
        "    if lines is not None:\n",
        "        for x1, y1, x2, y2 in lines[:,0]:\n",
        "            cv2.line(grid_detected_img, (x1,y1),(x2,y2),(0,255,0),1)\n",
        "    print(f\"Step 3: Grid detected - {len(horizontal_lines)} horizontal, {len(vertical_lines)} vertical lines\")\n",
        "    cv2_imshow(grid_detected_img)\n",
        "\n",
        "    # --- Step 4: Reconstruct grid ---\n",
        "    def cluster_positions(positions, tolerance=3):\n",
        "        if not positions:\n",
        "            return []\n",
        "        positions = sorted(positions)\n",
        "        clusters = []\n",
        "        current_cluster = [positions[0]]\n",
        "        for pos in positions[1:]:\n",
        "            if abs(pos - current_cluster[-1]) <= tolerance:\n",
        "                current_cluster.append(pos)\n",
        "            else:\n",
        "                clusters.append(int(np.mean(current_cluster)))\n",
        "                current_cluster = [pos]\n",
        "        clusters.append(int(np.mean(current_cluster))) # Add the last cluster\n",
        "        return clusters\n",
        "\n",
        "    h_lines_unique = cluster_positions([line[1] for line in horizontal_lines])\n",
        "    v_lines_unique = cluster_positions([line[0] for line in vertical_lines])\n",
        "    data.metadata[\"h_lines_unique\"] = h_lines_unique\n",
        "    data.metadata[\"v_lines_unique\"] = v_lines_unique\n",
        "\n",
        "    grid_reconstructed = img.copy()\n",
        "    for y in h_lines_unique:\n",
        "        cv2.line(grid_reconstructed, (0,y),(w_img,y),(255,0,0),1)\n",
        "    for x in v_lines_unique:\n",
        "        cv2.line(grid_reconstructed, (x,0),(x,h_img),(255,0,0),1)\n",
        "    print(f\"Step 4: Grid reconstructed - {len(h_lines_unique)} horizontal, {len(v_lines_unique)} vertical lines\")\n",
        "    cv2_imshow(grid_reconstructed)\n",
        "\n",
        "    # --- Store the image with the grid for potential later use ---\n",
        "    # The example usage expects 'warped' key, so setting it here as the main output of this processor\n",
        "    data.metadata[\"warped\"] = grid_reconstructed\n",
        "    data.image = grid_reconstructed # Pass the image with reconstructed grid to the next processor\n",
        "\n",
        "    # --- Step 5a: Grayscale with red grid removed --- # (Moved to 5a for consistency)\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray_no_grid = gray_img.copy()\n",
        "    gray_no_grid[red_mask_clean > 0] = 255\n",
        "    data.metadata[\"gray_no_grid\"] = gray_no_grid\n",
        "    print(\"Step 5a: Grayscale with red grid removed (for curve detection)\")\n",
        "    cv2_imshow(gray_no_grid)\n",
        "\n",
        "    # --- Step 5b: Thresholded ECG lines (grid removed) --- # (Added to metadata)\n",
        "    # Now threshold to detect ECG line (black line -> white)\n",
        "    # Adaptive threshold is robust to lighting\n",
        "    thresh_ecg = cv2.adaptiveThreshold(\n",
        "        gray_no_grid,\n",
        "        255,\n",
        "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "        cv2.THRESH_BINARY_INV,\n",
        "        blockSize=15,\n",
        "        C=10\n",
        "    )\n",
        "\n",
        "    data.metadata[\"thresh_ecg\"] = thresh_ecg\n",
        "    print(\"Step 5b: Thresholded ECG lines (grid removed)\")\n",
        "    cv2_imshow(thresh_ecg)\n",
        "\n",
        "    return data\n",
        "\n",
        "class CurveDetectPerfect(Processor):\n",
        "  def process(self, data:ImageData) -> ImageData:\n",
        "    img = data.metadata[\"cropped\"].copy()\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    gray = hsv[:, :, 2]\n",
        "    mask = gray < 60\n",
        "    img[mask] = 0\n",
        "    img[~mask] = 255\n",
        "    cv2_imshow(img)\n",
        "\n",
        "    def bfs_component(image, start_x, start_y, n, threshold, visited):\n",
        "      h, w = image.shape\n",
        "      half = n // 2\n",
        "\n",
        "      queue = deque([(start_x, start_y)])\n",
        "      component = []\n",
        "      visited[start_y, start_x] = True\n",
        "\n",
        "      while queue:\n",
        "          x, y = queue.popleft()\n",
        "          component.append((x, y))\n",
        "\n",
        "          for dy in range(-half, half + 1):\n",
        "              for dx in range(-half, half + 1):\n",
        "                  nx, ny = x + dx, y + dy\n",
        "\n",
        "                  if (\n",
        "                      0 <= nx < w and\n",
        "                      0 <= ny < h and\n",
        "                      not visited[ny, nx] and\n",
        "                      image[ny, nx] < threshold\n",
        "                  ):\n",
        "                      visited[ny, nx] = True\n",
        "                      queue.append((nx, ny))\n",
        "\n",
        "      return component\n",
        "\n",
        "    def find_all_dark_components(image, n, threshold=50):\n",
        "      h, w = image.shape\n",
        "      visited = np.zeros((h, w), dtype=bool)\n",
        "      components = []\n",
        "\n",
        "      for y in range(h):\n",
        "          for x in range(w):\n",
        "              if image[y, x] < threshold and not visited[y, x]:\n",
        "                  component = bfs_component(\n",
        "                      image=image,\n",
        "                      start_x=x,\n",
        "                      start_y=y,\n",
        "                      n=n,\n",
        "                      threshold=threshold,\n",
        "                      visited=visited\n",
        "                  )\n",
        "                  components.append(np.array(component))\n",
        "\n",
        "      return components\n",
        "\n",
        "    components = find_all_dark_components(gray, 5, 100)\n",
        "\n",
        "    def draw_components_cv(image_gray, components):\n",
        "      # Convert grayscale â†’ BGR\n",
        "      img_color = cv2.cvtColor(image_gray, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "      for comp in components:\n",
        "          # random color per component\n",
        "          color = tuple(np.random.randint(0, 255, 3).tolist())\n",
        "\n",
        "          for (x, y) in comp:\n",
        "              img_color[y, x] = color   # fastest way (single pixel)\n",
        "\n",
        "      return img_color\n",
        "    components = find_all_dark_components(\n",
        "        image=gray,\n",
        "        n=5,\n",
        "        threshold=50\n",
        "    )\n",
        "\n",
        "    overlay = draw_components_cv(gray, components)\n",
        "\n",
        "    cv2_imshow(overlay)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "class TreatImage():\n",
        "  def __init__(self,processors : list[Processor]) -> None:\n",
        "    self.processors = processors\n",
        "\n",
        "  def run(self, image) -> ImageData:\n",
        "    data = ImageData(image, {})\n",
        "    for processor in self.processors:\n",
        "      data = processor.process(data)\n",
        "    return data\n",
        "\n",
        "'''\n",
        "treat = TreatImage([Crop(),GridDetect(),CurveDetect()])\n",
        "treat.run(img)\n",
        "'''\n",
        "# Change img_path to match the one used in the previous cell's execution for consistency.\n",
        "img_path = \"data/test/1053922973.png\"\n",
        "\n",
        "test = TreatImage([Crop(), CurveDetectPerfect()])\n",
        "res = test.run(cv2.imread(img_path))\n",
        "\n",
        "# Optional: Display final outputs stored in metadata if desired\n",
        "# cv2_imshow(res.metadata[\"cropped\"])\n",
        "# print(res.metadata.get(\"paper_contour\"))\n",
        "# cv2_imshow(res.metadata[\"warped\"])\n",
        "# cv2_imshow(res.metadata[\"gray_no_grid\"])\n",
        "# cv2_imshow(res.metadata[\"thresh_ecg\"])\n",
        "# If you want to see the overlaid image directly from metadata:\n",
        "# cv2_imshow(res.metadata[\"ecg_traces_overlaid_image\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pt2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}