{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!rm -rf clone && git clone https://github.com/rusgu-real/ecg_digitisation clone && cp -a clone/. ."
      ],
      "metadata": {
        "id": "Yt_ZVOaTgbIP",
        "outputId": "3619b575-9518-420c-cbd2-687b5147ce86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'clone'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 36 (delta 6), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (36/36), 24.34 MiB | 9.56 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Hr-InVuk9g3b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# --- Chargement image ---\n",
        "img = cv2.imread(\"data/test/145375843-0009.png\")  # <-- mets ton chemin ici\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# --- Binarisation adaptative ---\n",
        "bin_img = cv2.adaptiveThreshold(\n",
        "    gray,\n",
        "    255,\n",
        "    cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "    cv2.THRESH_BINARY_INV,\n",
        "    blockSize=31,\n",
        "    C=5\n",
        ")\n",
        "\n",
        "# --- Extraction des lignes horizontales ---\n",
        "horiz_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (50, 1))\n",
        "horiz = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, horiz_kernel)\n",
        "\n",
        "# --- Extraction des lignes verticales ---\n",
        "vert_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 50))\n",
        "vert = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, vert_kernel)\n",
        "\n",
        "# --- Grille finale ---\n",
        "grid = cv2.bitwise_or(horiz, vert)\n",
        "\n",
        "# --- Affichage ---\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(grid, cmap=\"gray\")\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Grille détectée (courbe supprimée)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TLuvRXPLg1CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Load image and resize ---\n",
        "img = cv2.imread(\"data/test/145375843-0009.png\")\n",
        "if img is None:\n",
        "    raise IOError(\"Image not found\")\n",
        "\n",
        "img = cv2.resize(img, None, fx=0.7, fy=0.7)\n",
        "h_img, w_img = img.shape[:2]\n",
        "\n",
        "cv2_imshow(img)\n",
        "print(\"Original Image shape:\", img.shape)\n",
        "\n",
        "# --- 2. Convert to HSV and create lenient red mask ---\n",
        "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "lower_red1 = np.array([0, 50, 50])\n",
        "upper_red1 = np.array([10, 255, 255])\n",
        "lower_red2 = np.array([170, 50, 50])\n",
        "upper_red2 = np.array([180, 255, 255])\n",
        "\n",
        "mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
        "mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
        "red_mask = cv2.bitwise_or(mask1, mask2)\n",
        "\n",
        "# Minimal morphology to remove tiny noise\n",
        "kernel = np.ones((2, 2), np.uint8)\n",
        "red_mask_clean = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "\n",
        "cv2_imshow(red_mask_clean)\n",
        "print(\"Red mask cleaned\")\n",
        "\n",
        "# --- 3. Edge detection ---\n",
        "edges = cv2.Canny(red_mask_clean, 20, 60)\n",
        "cv2_imshow(edges)\n",
        "print(\"Edges detected\")\n",
        "\n",
        "# --- 4. Hough line detection (lenient) ---\n",
        "lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=20, minLineLength=20, maxLineGap=15)\n",
        "grid_img = img.copy()\n",
        "horizontal_lines = []\n",
        "vertical_lines = []\n",
        "\n",
        "if lines is not None:\n",
        "    for x1, y1, x2, y2 in lines[:,0]:\n",
        "        if abs(y1 - y2) < 5:\n",
        "            horizontal_lines.append((x1, y1, x2, y2))\n",
        "            cv2.line(grid_img, (x1, y1), (x2, y2), (0,255,0), 1)\n",
        "        elif abs(x1 - x2) < 5:\n",
        "            vertical_lines.append((x1, y1, x2, y2))\n",
        "            cv2.line(grid_img, (x1, y1), (x2, y2), (0,255,0), 1)\n",
        "\n",
        "cv2_imshow(grid_img)\n",
        "print(\"Grid detection done: {} horizontal, {} vertical lines\".format(len(horizontal_lines), len(vertical_lines)))\n",
        "\n",
        "# --- 5. Reconstruct grid ---\n",
        "def cluster_positions(positions, tolerance=3):\n",
        "    positions = sorted(positions)\n",
        "    clusters = []\n",
        "    current_cluster = [positions[0]]\n",
        "    for pos in positions[1:]:\n",
        "        if abs(pos - current_cluster[-1]) <= tolerance:\n",
        "            current_cluster.append(pos)\n",
        "        else:\n",
        "            clusters.append(int(np.mean(current_cluster)))\n",
        "            current_cluster = [pos]\n",
        "    clusters.append(int(np.mean(current_cluster)))\n",
        "    return clusters\n",
        "\n",
        "h_positions = [line[1] for line in horizontal_lines]\n",
        "v_positions = [line[0] for line in vertical_lines]\n",
        "\n",
        "h_lines_unique = cluster_positions(h_positions)\n",
        "v_lines_unique = cluster_positions(v_positions)\n",
        "\n",
        "# Overlay reconstructed grid\n",
        "grid_reconstructed = img.copy()\n",
        "for y in h_lines_unique:\n",
        "    cv2.line(grid_reconstructed, (0, y), (w_img, y), (255,0,0), 1)\n",
        "for x in v_lines_unique:\n",
        "    cv2.line(grid_reconstructed, (x,0), (x,h_img), (255,0,0), 1)\n",
        "\n",
        "cv2_imshow(grid_reconstructed)\n",
        "print(\"Grid reconstructed: {} horizontal, {} vertical lines\".format(len(h_lines_unique), len(v_lines_unique)))\n",
        "\n",
        "# --- 6. Extract ECG waveforms ---\n",
        "# Create pixel-to-voltage mapping\n",
        "v_spacing_px = int(np.median(np.diff(h_lines_unique)))\n",
        "h_spacing_px = int(np.median(np.diff(v_lines_unique)))\n",
        "\n",
        "# Split vertical grid into 4 regions (assuming 4 ECG traces stacked)\n",
        "num_traces = 4\n",
        "trace_height = h_img // num_traces\n",
        "\n",
        "ecg_traces = []\n",
        "\n",
        "for i in range(num_traces):\n",
        "    y_start = i * trace_height\n",
        "    y_end = (i+1) * trace_height\n",
        "    ecg_crop = img[y_start:y_end, :, :]\n",
        "\n",
        "    # Convert to grayscale and invert (ECG is darker than background)\n",
        "    gray = cv2.cvtColor(ecg_crop, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.bitwise_not(gray)\n",
        "\n",
        "    # Threshold to get ECG line\n",
        "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Get waveform as pixel coordinates\n",
        "    xs = np.arange(thresh.shape[1])\n",
        "    ys = []\n",
        "    for x in xs:\n",
        "        column = thresh[:, x]\n",
        "        if np.any(column > 0):\n",
        "            y_pos = np.argmax(column > 0)\n",
        "            ys.append(y_pos)\n",
        "        else:\n",
        "            ys.append(np.nan)  # missing data\n",
        "    ecg_traces.append((xs, np.array(ys)))\n",
        "\n",
        "    # Plot waveform\n",
        "    plt.figure(figsize=(12,2))\n",
        "    plt.plot(xs, ys)\n",
        "    plt.title(f\"ECG Trace {i+1}\")\n",
        "    plt.gca().invert_yaxis()  # match image coordinates\n",
        "    plt.show()\n",
        "\n",
        "print(\"ECG extraction done\")\n"
      ],
      "metadata": {
        "id": "dooj9JoY5sLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Step 0: Load and resize image ---\n",
        "img = cv2.imread(\"data/test/145375843-0009.png\")\n",
        "if img is None:\n",
        "    raise IOError(\"Image not found\")\n",
        "img = cv2.resize(img, None, fx=0.7, fy=0.7)\n",
        "h_img, w_img = img.shape[:2]\n",
        "\n",
        "cv2_imshow(img)\n",
        "print(\"Step 0: Original Image\")\n",
        "\n",
        "# --- Step 1: Detect red grid mask ---\n",
        "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "lower_red1 = np.array([0,50,50])\n",
        "upper_red1 = np.array([10,255,255])\n",
        "lower_red2 = np.array([170,50,50])\n",
        "upper_red2 = np.array([180,255,255])\n",
        "mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
        "mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
        "red_mask = cv2.bitwise_or(mask1, mask2)\n",
        "\n",
        "# Minimal morphology to clean noise\n",
        "kernel = np.ones((2,2),np.uint8)\n",
        "red_mask_clean = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "\n",
        "cv2_imshow(red_mask_clean)\n",
        "print(\"Step 1: Red grid mask cleaned\")\n",
        "\n",
        "# --- Step 2: Edge detection ---\n",
        "edges = cv2.Canny(red_mask_clean, 20, 60)\n",
        "cv2_imshow(edges)\n",
        "print(\"Step 2: Edges detected\")\n",
        "\n",
        "# --- Step 3: Detect Hough lines ---\n",
        "lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=20, minLineLength=20, maxLineGap=15)\n",
        "grid_detected = img.copy()\n",
        "horizontal_lines = []\n",
        "vertical_lines = []\n",
        "if lines is not None:\n",
        "    for x1, y1, x2, y2 in lines[:,0]:\n",
        "        if abs(y1 - y2) < 5:\n",
        "            horizontal_lines.append((x1, y1, x2, y2))\n",
        "            cv2.line(grid_detected, (x1,y1),(x2,y2),(0,255,0),1)\n",
        "        elif abs(x1 - x2) < 5:\n",
        "            vertical_lines.append((x1, y1, x2, y2))\n",
        "            cv2.line(grid_detected, (x1,y1),(x2,y2),(0,255,0),1)\n",
        "\n",
        "cv2_imshow(grid_detected)\n",
        "print(f\"Step 3: Grid detected - {len(horizontal_lines)} horizontal, {len(vertical_lines)} vertical lines\")\n",
        "\n",
        "# --- Step 4: Reconstruct grid ---\n",
        "def cluster_positions(positions, tolerance=3):\n",
        "    positions = sorted(positions)\n",
        "    clusters = []\n",
        "    current_cluster = [positions[0]]\n",
        "    for pos in positions[1:]:\n",
        "        if abs(pos - current_cluster[-1]) <= tolerance:\n",
        "            current_cluster.append(pos)\n",
        "        else:\n",
        "            clusters.append(int(np.mean(current_cluster)))\n",
        "            current_cluster = [pos]\n",
        "    clusters.append(int(np.mean(current_cluster)))\n",
        "    return clusters\n",
        "\n",
        "h_lines_unique = cluster_positions([line[1] for line in horizontal_lines])\n",
        "v_lines_unique = cluster_positions([line[0] for line in vertical_lines])\n",
        "\n",
        "grid_reconstructed = img.copy()\n",
        "for y in h_lines_unique:\n",
        "    cv2.line(grid_reconstructed, (0,y),(w_img,y),(255,0,0),1)\n",
        "for x in v_lines_unique:\n",
        "    cv2.line(grid_reconstructed, (x,0),(x,h_img),(255,0,0),1)\n",
        "\n",
        "cv2_imshow(grid_reconstructed)\n",
        "print(f\"Step 4: Grid reconstructed - {len(h_lines_unique)} horizontal, {len(v_lines_unique)} vertical lines\")\n",
        "\n",
        "5# Convert to grayscale\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Remove red grid by using the red mask\n",
        "# Any pixel that is part of the red grid -> set to 255 (white)\n",
        "gray_no_grid = gray.copy()\n",
        "gray_no_grid[red_mask_clean > 0] = 255\n",
        "\n",
        "cv2_imshow(gray_no_grid)\n",
        "print(\"Step 5a: Grayscale with red grid removed\")\n",
        "\n",
        "# Now threshold to detect ECG line (black line -> white)\n",
        "# Adaptive threshold is robust to lighting\n",
        "thresh_ecg = cv2.adaptiveThreshold(\n",
        "    gray_no_grid,\n",
        "    255,\n",
        "    cv2.ADAPTIVE_THRESH_MEAN_C,\n",
        "    cv2.THRESH_BINARY_INV,\n",
        "    blockSize=15,\n",
        "    C=10\n",
        ")\n",
        "\n",
        "threshold_value = 50  # adjust depending on your ECG darkness\n",
        "thresh_ecg = np.zeros_like(gray_no_grid, dtype=np.uint8)\n",
        "thresh_ecg[gray_no_grid < threshold_value] = 255  # ECG lines become white\n",
        "\n",
        "\n",
        "cv2_imshow(thresh_ecg)\n",
        "print(\"Step 5b: Thresholded ECG lines (grid removed)\")\n",
        "\n",
        "# Find contours of ECG traces\n",
        "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "# Filter and sort contours by vertical position\n",
        "ecg_traces = []\n",
        "for cnt in contours:\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    if w > w_img//20:  # skip small noise\n",
        "        ecg_traces.append((x, y, w, h))\n",
        "ecg_traces = sorted(ecg_traces, key=lambda t: t[1])\n",
        "\n",
        "# Step 5b: Extract pixel coordinates and plot each trace\n",
        "for i, (x, y, w, h) in enumerate(ecg_traces):\n",
        "    crop = thresh[y:y+h, x:x+w]\n",
        "    xs = np.arange(crop.shape[1])\n",
        "    ys = []\n",
        "    for col in range(crop.shape[1]):\n",
        "        column = crop[:, col]\n",
        "        if np.any(column > 0):\n",
        "            y_pos = np.argmax(column > 0)\n",
        "            ys.append(y_pos)\n",
        "        else:\n",
        "            ys.append(np.nan)\n",
        "    ys = np.array(ys)\n",
        "    plt.figure(figsize=(12,2))\n",
        "    plt.plot(xs, ys)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.title(f\"Step 5b: ECG Trace {i+1}\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "ow9cmffj6hEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "class ImageData:\n",
        "    def __init__(self, image, metadata=None):\n",
        "        self.image = image\n",
        "        self.metadata = metadata\n",
        "\n",
        "class Processor(ABC):\n",
        "  @abstractmethod\n",
        "  def process(self, data:ImageData) -> ImageData:\n",
        "    pass\n",
        "\n",
        "class Crop(Processor):\n",
        "  pass\n",
        "\n",
        "class GridDetect(Processor):\n",
        "  pass\n",
        "\n",
        "class CurveDetect(Processor):\n",
        "  pass\n",
        "\n",
        "class TreatImage(Processor):\n",
        "  def __init__(self,processors : list[Processor]) -> None:\n",
        "    self.processors = processors\n",
        "\n",
        "  def run(self, image) -> dict:\n",
        "    data = ImageData(image, {})\n",
        "    for processor in self.processors:\n",
        "      data = processor.process(data)\n",
        "\n",
        "'''\n",
        "treat = TreatImage([Crop(),GridDetect(),CurveDetect()])\n",
        "treat.run(img)\n",
        "'''\n"
      ],
      "metadata": {
        "id": "3aqvZnvawg0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pt2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}